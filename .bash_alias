#!/usr/bin/env bash
# Helpers

source_as_root() {
    # source_as_root <script name> <function in script to run>
    # e.g. source_as_root ~/bin/my_scripts.sh function_name
    #
    # WARNING: This will source the file and run it with sudo
    # Only run this on scripts that only define functions
    local wifi_source=$(readlink -f $1)
    sudo /bin/bash -c "source ${wifi_source}; $2"
}

# Diagnostics

# Show the TCP and UDP ports being listened on with the process associated, user, etc.

alias lport="sudo netstat -lepunt"


# ...fix empty...


# View HTTP traffic

#alias sniff="sudo ngrep -d 'en1' -t '^(GET|POST) ' 'tcp and port 80'"
#alias httpdump="sudo tcpdump -i en1 -n -s 0 -w - | grep -a -o -E \"Host\: .*|GET \/.*\""

# Simple Servers

# run simple python server from directory


alias simpleServer="python -m SimpleHTTPServer"


# ...fix empty...

# Use simple python server to view jekyll site from _all directory. Useful for when you use SVG's as much as I do.

alias jserver="cd ..; jekyll --no-server; cd _site; simpleServer"

# Connecting to other devices
# OpenWRT easy ssh and scp node Alias's

alias oscp='scp -o "UserKnownHostsFile /dev/null" -o "StrictHostKeyChecking no"'
alias ossh='ssh -o "UserKnownHostsFile /dev/null" -o "StrictHostKeyChecking no"'

# Screen into BeagleBone Black with a console cable

alias bbscreen="sudo screen /dev/ttyUSB0 115200"

# WiFi AccessPoint Commands

alias you_dont_know_me="source_as_root ~/dotfiles/bin/wifi_management.sh reset_wifi_with_changed_mac"
alias new_wireless_mac=="source_as_root ~/dotfiles/bin/wifi_management.sh reset_wifi_with_changed_mac"
alias not_the_droids=="source_as_root ~/dotfiles/bin/wifi_management.sh reset_wifi_with_changed_mac"


# Get Current WiFi PSK Key
get_current_wifi_psk_key() {
    c='cut -d: -f2';
    g=grep;
    a=$(nmcli -t -f ACTIVE,SSID d w l|$g -E "^yes:"|$c);
    p=$(nmcli -s -t c show $a|$g psk:|$c);
    python3 -c "from hashlib import pbkdf2_hmac as p; from binascii import hexlify as h;print('PSK',h(p('sha1', b'$p', b'$a', 4096, dklen=32)).decode('ascii'))"
}

# Scraping


alias listserv='time ~/.bin/get_listserv'


# ...fix empty...



get_site_links() {
    local SITE=${1}
    wget -w 1 --no-check-certificate --spider -r ${SITE} 2>&1 | grep '^--' | awk '{ print $3 }' | grep -v '\.\(css\|js\|png\|gif\|jpg\|JPG\)$' > urls.txt
}

get_song_from_youtube() {
      local SITE=${1}
      local LOCATION=$(pwd)
      cd ~/Music
      youtube-dl --audio-format mp3 -x ${SITE}
      cd ${LOCATION}
  }
alias getsong=get_song_from_youtube

# Terminal and Navigation
# Alias' for easier navigation

alias ll='ls -alF'
alias la='ls -A'
alias l='ls -CF'
alias ..='cd ..'
alias ...='cd ../..'
alias cd=cd_func



# cd function for providing easy movement and history.


cd_func ()
{
  local x2 the_new_dir adir index
  local -i cnt

  if [[ $1 ==  "--" ]]; then
    dirs -v
    return 0
  fi

  the_new_dir=$1
  [[ -z $1 ]] && the_new_dir=$HOME

  if [[ ${the_new_dir:0:1} == '-' ]]; then
    #
    # Extract dir N from dirs
    index=${the_new_dir:1}
    [[ -z $index ]] && index=1
    adir=$(dirs +$index)
    [[ -z $adir ]] && return 1
    the_new_dir=$adir
  fi

  # '~' has to be substituted by ${HOME}
  [[ ${the_new_dir:0:1} == '~' ]] && the_new_dir="${HOME}${the_new_dir:1}"

  # Now change to the new dir and add to the top of the stack
  pushd "${the_new_dir}" > /dev/null
  [[ $? -ne 0 ]] && return 1
  the_new_dir=$(pwd)

  # Trim down everything beyond 11th entry
  popd -n +11 2>/dev/null 1>/dev/null

  # Remove any other occurence of this dir, skipping the top of the stack
  for ((cnt=1; cnt <= 10; cnt++)); do
    x2=$(dirs +${cnt} 2>/dev/null)
    [[ $? -ne 0 ]] && return 0
    [[ ${x2:0:1} == '~' ]] && x2="${HOME}${x2:1}"
    if [[ "${x2}" == "${the_new_dir}" ]]; then
      popd -n +$cnt 2>/dev/null 1>/dev/null
      cnt=cnt-1
    fi
  done

  return 0
}

# Colorize Terminal
# Colorize Logs

if [ -f "/usr/bin/ccze" ]; then
    lesslog() { ccze -A < $1 | less -R; }
    taillog() { tail -f $1 | ccze -A; }
fi



# Colorize Less


alias lesc='LESS="-R" LESSOPEN="|pygmentize -g %s" less'

# Pranks & Misc


alias rainbow='for i in {1..665535};do printf "%x\n" $i;done|while read -r u;do printf "\033[38;5;$((16+$((16#$u))%230))m\u$u\033[0m";done'


# ...fix empty...


whitenoise() { aplay -c 2 -f S16_LE -r 44100 /dev/urandom ;}


# ...fix empty...


# This is just a stub that can be modified to work better
# with different photos
annotate() {
    # annotate [image_name] "[annotation]"
    # produces text_[image_name] file
    # ONLY use this in the same directory as the image.

    local image_name=$1
    local annotation=$2

    # North, South, East, West
    # NorthEast, SouthWest, Etc.
    local gravity="East"
    # Font Selection
    # See all with following command
    # convert -list font | grep "Font:"
    local font="Droid-Sans"
    local pointsize=25
    # Fold the text at a certain char
    # change this to make the text wrap
    local foldchar=15
    # This makes it only fold on spaces
    local spacefold="-s"
    # This would make it not fold.
    # local spacefold=""

    convert -gravity $gravity \
            -weight 800 \
            -font $font -pointsize $pointsize \
            -annotate +20+20 "$(fold -w ${foldchar} ${spacefold} <<< "${annotation}")" \
            "$image_name" text_"$image_name"
}

# mkproj
# Creates a directory structure for a possible new project

make_project() {
    mkdir $1
    cd $1
    mkdir proposals
    mkdir agreement
    mkdir reports
    mkdir correspondence
    mkdir procurement
    mkdir travel
    mkdir workplans
    mkdir monitoring_and_evaluation
    mkdir outreach_comms
    mkdir meetings
    mkdir budgets
    mkdir outputs
    touch .projectile
    touch tasks.org
    cd ../
}
alias mkproj=make_project

# Whiteboard Cleaning

# white-board-cleaner () {
#     wbtempdir=$(mktemp -d "${TMPDIR:-/tmp/}$(basename 0).XXXXXXXXXXXX")
#     convert "$1" -morphology Convolve DoG:15,100,0 -negate -normalize -blur 0x1 -channel RBG -level 60%,91%,0.1 "${wbtempdir}/wb_image.png" ;

#     ./autotrace \
#         --dpi 1024 \
#         --line-threshold 0.1 \
#         --color-count 16 \
#         --corner-always-threshold 60 \
#         --line-reversion-threshold 0.1 \
#         --width-weight-factor 0.1 \
#         --despeckle-level 10 \
#         --despeckle-tightness 5 \
#         --preserve-width \
#         --remove-adjacent-corners \
#         --output-format svg \
#         --output-file $2 \
#         "${wbtempdir}/wb_image.png"
# }
# trap "rm -rf $wbtempdir" EXIT

white-board-cleaner () {
    convert "$1" -morphology Convolve DoG:15,100,0 -negate -normalize -blur 0x1 -channel RBG -level 60%,91%,0.1 "$2" ;
}

# Coding

# Alias git

alias g=git

# Git Go!
# Run a git command in another directory
# gg /path/to/repo [git command]
function gg() {
   local _gg="$1";
   shift;
   git --git-dir="${_gg}/.git" --work-tree="${_gg}" "$@"
}


# ...fix empty...

# URL-encode strings

alias urlencode='python -c "import sys, urllib as ul; print ul.quote_plus(sys.argv[1]);"'

# Urldecode strings
alias urldecode='sed "s@+@ @g;s@%@\\\\x@g" | xargs -0 printf "%b"'

# i3
i3-rename() {
  local WORKSPACE=$(i3-msg -t get_workspaces | jq -r '.[] | select(.focused==true).name')
  i3-msg rename workspace "${WORKSPACE}" to "${1}"
}
alias i3r=i3-rename

# Installed
# find installed files (good for grepping for dependencies. "installed |grep DEPEN")
alias installed_find='dpkg --get-selections | grep -v deinstall'
alias installed=installed_find
installed_check() {
    PKG_NAME="$1"
    is_installed=$(dpkg-query -W --showformat='${Status}\n' "${PKG_NAME}" 2>/dev/null | grep "install ok installed") || true
    if [[ $is_installed == "install ok installed" ]]; then
        (>&2 echo "Package installed")
        return 0
    else
        (>&2 echo "Package not found")
        return 1
    fi
}

# Alert
# Add an "alert" alias for long running commands.  Use like so: sleep 10; alert
alias alert='notify-send --urgency=low -i "$([ $? = 0 ] && echo terminal || echo error)" "$(history|tail -n1|sed -e '\''s/^\s*[0-9]\+\s*//;s/[;&|]\s*alert$//'\'')"'

# Hide mistaken history commands
# # Hide the previous command you just ran and forgot to use space.
alias hideprev='history -d $((HISTCMD-2)) && history -d $((HISTCMD-1))'


# Un-delete File
undel_func(){
        echo "Searching for deleted file with string $1"
        # *"Attempt"* to recover an accidentally removed file.
        sudo fgrep --binary-files=text -C 2000 "$1" /dev/sda > recovereddata.out
}
alias undelete=undel_func


# recover deleted media files from external device
# repair mp4's on that device
undel_media() {
    #sudo foremost -i /dev/sdd1 -o ~/temp/media
    local INPUT="$1"
    local OUTPUT_PATH="$2"
    sudo foremost -i ${INPUT} -o ${OUTPUT_PATH}
    sudo chown -R s2e ${OUTPUT_PATH}
    cd ${OUTPUT_PATH}/mp4
    # Repair all mp4's found
    find . |grep xargs -I % ffmpg -i % -o %.new.mp4
    # TODO - Run repair function on all media
}

# DD-Status

# Get the status of a currently running dd process
# Use in a terminal NOT running the current dd!
# Usage: ddstat
#alias ddstat="sudo kill -USR1 `pgrep -l '^dd$' | cut -f 1 -d \" \"`"
alias ddstat="sudo progress -m"

# Burn USB with alert

burnusb() {
        sudo dd if=$1 of=$2 bs=4M conv=sync
        sync
        ding
        notify-send -u critical 'burnusb' 'done'
}


# Extract a compressed file
extract() {
        if [ -f $1 ] ; then
                case $1 in
                        *.tar.bz2) tar xvjf $1 ;;
                        *.tar.gz) tar xvzf $1 ;;
                        *.tar.xz) tar xvJf $1 ;;
                        *.xz) unxz -v $1 ;;
                        *.bz2) bunzip2 $1 ;;
                        *.rar) unrar x $1 ;;
                        *.gz) gunzip $1 ;;
                        *.tar) tar xvf $1 ;;
                        *.tbz2) tar xvjf $1 ;;
                        *.tgz) tar xvzf $1 ;;
                        *.zip) unzip $1 ;;
                        *.Z) uncompress $1;;
                        *.7z) 7z x $1 ;;
                        *) echo "'$1' cannot be extracted via >extract<" ;;
                esac
        else
                echo "'$1' is not a valid file"
        fi
}


unzip_long_name() {
    ZIPFILE="$1"
    LONG_NAME="$2"

    long_fname=${LONG_NAME%.*}
    unzip -p -j -c "$ZIPFILE" "$LONG_NAME" > "${long_fname:0:250}.${LONG_NAME##*.}"
}

unzip_all_long_names() {
    zipinfo -2 "$1" | while read i;
    do
        long_fname=${i%.*}
        unzip -p -j -c "$1" "$i" > "${long_fname:0:250}.${i##*.}"
    done;
}

# Grab a compressed file from online and uncompress it

curltar() {
        case $1 in
                *.tar.bz2) \curl -kL $1 | tar xvjf - ;;
                *.tar.gz) \curl -kL $1 | tar xvzf - ;;
                *.bz2) \curl -kL $1 | bunzip2 - ;;
                *.rar) \curl -kL $1 | unrar x - ;;
                *.gz) \curl -kL $1 | gunzip - ;;
                *.tar) \curl -kL $1 | tar xvf - ;;
                *.tbz2) \curl -kL $1 | tar xvjf - ;;
                *.tgz) \curl -kL $1 | tar xvzf - ;;
                *.zip) \curl -kL $1 | unzip - ;;
                *.Z) \curl -kL $1 | uncompress - ;;
                *.7z) \curl -kL $1 | 7z x - ;;
                *) \curl -kLO $1
        esac
}

curl_w_resume() {
    # From the following one liner
    # export ec=18; while [ $ec -eq 18 ]; do /usr/bin/curl -O -C - "http://..........zip"; export ec=$?; done
    local url="${1}"
    local ec=18;
    while [ $ec -eq 18 ]; do
        curl -O -C - "${url}";
        ec=$?;
    done
}

###########################################################################
## GIT
###########################################################################

# Git Branch Parsing

function parse_git_branch() {
    git branch --no-color 2> /dev/null | sed -e '/^[^*]/d' -e 's/* \(.*\)/(\1) /'
}

# Git purge file
# Use filter-branch to remove an unwanted file/directory from a repo's git revision history.


git_purge() {
git filter-branch --prune-empty --index-filter "git rm -rf --cached --ignore-unmatch ${1}" --tag-name-filter cat -- --all
}

git_fpurge() {
git filter-branch -f --prune-empty --index-filter "git rm -rf --cached --ignore-unmatch ${1}" --tag-name-filter cat -- --all
}

# github stats
gitstats() {
    local user="$1"
  python ~/dotfiles/bin/github_traffic.py --log --user "${user}" --write ~/temp/github
}

###########################################################################
## GPG
###########################################################################
# === GPG find who a file is encryped to ===

# List who some gpg data is encrypted to
# Only works if the client puts key IDs into encrypted packets
# But, most clients do
# Regex Snippets
#
# Match Fingerprint
# MATCHES: 0xAABBCCDD11223344
# REGEX: \(0x[A-Z0-9]\{16\}\)
#
# Match Quoted Name
# MATCHES:       "Seamus Tuohy <code@seamustuohy.com>"
# REGEX: \s*\"\([^\"]*\"\).*
alias gpg-encrypted-to="gpg --batch --list-packets 2>&1 \
            | sed -n \
                  '/\(0x[A-Z0-9]\{16\}\)/{ # Match first line
                    # Append next input line to contents of pattern space
                    $!{ N
                      # sed substitution pattern that works on merged lines
                      s/.*\(0x[A-Z0-9]\{16\}\).*\n\s*\"\([^\"]*\"\).*/\2 - \1/
                      # substitution successful -> goto label :found
                      t found
                      # substitution failed (match not found)
                      :not-found
                      # if no match, delete line
                      d
                      # substitution successful (match found)
                      :found
                      # print substitution for match
                      p
                      }
                    }'"

alias gpg-encrypted-to-keyid="gpg --batch --list-packets 2>&1 \
                             | grep -oE 'keyid [A-Z0-9]{16}'| cut -d' ' -f2"

alias gpg-file-encrypted-to=gpg-file-encrypted-to.sh
gpg-unlock-key() {
    echo "TEST" | gpg -ear "$1" | gpg -d
}


###########################################################################
## Crontab
###########################################################################
crontab_add() {
    (crontab -l ; echo "$1") 2>&1 \
        | grep -v "no crontab" \
        | sort | uniq \
        | crontab -
}

crontab_delete() {
    (crontab -l ; echo "$1") 2>&1 \
        | grep -v "no crontab" \
        | grep -v $1 \
        |  sort | uniq \
        | crontab -
}


# Find item in a Bash config file

# Look for relevant string in bash config files when things go weird
# $ grep_bash PATH
grep_bash(){
  for f in  ~/.bashrc ~/.profile ~/.bash_profile ~/.bash_login \
            /etc/profile /etc/environment /etc/bash.bashrc;
  do
    [ -e $f ] && grep -H "$@" $f;
  done
}

# Latex

inkscape2latex() {
    inkscape -D -z --file=${1}.svg --export-pdf=${1}.pdf --export-latex
}

# Identify what process (including its children) is eating up all my memory
alias psmem="sudo python ~/dotfiles/bin/ps_mem.py"

# Identify the top 10 processes eating up my CPU
alias whocpu="ps -eo pcpu,pid,user,args | sort -k 1 -r | head -10"


# Nuke All Metadata

nuke_all_metadata() {
    while true; do
        echo "This will erase the metadata from all files with extensions found in this folder."
        read -p "Do you really want to run this script? [y/n]" yn
        case $yn in
            [Yy]* ) local NUKEIT="true"; break;;
            [Nn]* ) local NUKEIT="NO";  break;;
            * ) echo "Please answer yes or no.";;
        esac
    done
    if [[ "${NUKEIT}" == "true" ]]; then
        for i in *.*;
        do echo "Nuking metadata for $i";
           exiftool -all= "$i";
        done
    fi
}



###########################################################################
## Time Warrior Aliases
###########################################################################

# What I Do?
# From https://github.com/drewstinnett/dotfiles/blob/master/.zshrc
alias whatd_i_do_last_week="task end.after:today-1wk completed rc.detection:off rc.defaultwidth:184"
alias whatd_i_do_last_month="task end.after:today-5wk completed rc.detection:off rc.defaultwidth:184"
alias whatd_i_do_last_day="task end.after:today-1d completed rc.detection:off rc.defaultwidth:184"
alias tk="task"
alias tko="task overdue"
alias tkm="task modify"
alias tka="task add"
alias tk_due_this_week="task due.before:today+1wk"
alias tk_due_tomorrow="task due.before:today+1day"


###########################################################################
## Reverse Engineering and Security Snippets
###########################################################################
get_all_site_links() {
    local URL="$1"
    local tmpdir=$(mktemp -dt "$(basename "$0").XXXXX")
    wget -m "${URL}" \
         --directory-prefix="${tmpdir}" \
         2>&1 \
        | grep '^--' \
        | awk '{ print $3 }' \
        | grep -v '\.\(css\|js\|png\|gif\|jpg\|JPG\)$'
    rm -fr "${tmpdir}"
}


msg2eml() {
    # Convert a .msg email to a .eml email
    # sudo apt-get install libemail-outlook-message-perl libemail-localdelivery-perl
    local MSG_FILE="${1}"
    local EML_FILE="${2}"
    ~/tools/msg2eml/msgconvert.pl --verbose --mbox "${EML_FILE}" "${MSG_FILE}"
}

get_shortened_from_viper_line() {
    # For reading shortened links copied from a pdf using viper `strings -N`
    local viper_line="$1"
    local url=$(echo  "${viper_line}" | sed 's/^ - .*\/URI (\(.*\)).*$/\1/')
    local location=$(curl -sI "${url}" | grep Location | cut -d : -f 2-)
    printf "%s,%s\n" "${url}" "${location}"
}

read_viper_url_file() {
    # $1 == url file
    # $2 == output file to write links to
    if [ $# -eq 2 ]; then
        echo "OVERWRITING FILE: $2"
        printf "Continue? "
        read
        echo "shortened_link,destination_url" > "$2"
    fi
    local filelen=$(wc -l "$1")
    iterator=0
    while IFS='' read -r viper_line || [[ -n "$viper_line" ]]; do
        local printable=$(get_shortened_from_viper_line "${viper_line}")
        if [ $# -eq 2 ]; then
            iterator=$(("$iterator" + 1))
            printf "Getting %s of ${filelen}\r" "$iterator"
            printf "%s\n" "${printable}" >> "$2"
        else
            printf "%s\n" "${printable}"
        fi
    done < "$1"
    printf "\n"
}

get_thug_from_viper_url_file() {
    # $1 == file from read_viper_url_file
    # $2 == output file to write location of thug data
    if [ $# -eq 2 ]; then
        echo "OVERWRITING FILE: $2"
        printf "Continue? "
        read
        echo "shortened_link,thug_data" > "$2"
    else
        printf "Please provide an output file \n"
        return 1
    fi
    # set -x
    local filelen=$(wc -l "$1" | cut -d ' ' -f1 )
    filelen=$(("$filelen" - 1))
    iterator=0
    # local url_list=$(sed 1,1d "$1")
    local url_list=$(sed 1,1d "$1" | cut -d , -f2 | sed '/^\s*$/d' | sort | uniq)
    # echo "$url_list"
    while IFS='' read -r url_line || [[ -n "$url_line" ]]; do
        iterator=$(("$iterator" + 1))
        #printf "%s,%s\n"
        local trimmed_url=$(echo "${url_line}" | tr -d '[:space:]')
        printf "Getting %s:\n %s of %s\n" "${trimmed_url}" "$iterator" "${filelen}"
        local output_path=$(thug_unassisted "${trimmed_url}" | grep "Thug Output Path" | sed 's/.*\(Thug Output Path: \)\(\/.*\).*$/\2/')
        printf "%s,%s\n" "${trimmed_url}" "${output_path}" >> "$2"
        #printf "%s,%s\n" "${url_line}" "${output_path}"
        # local printable=$(get_shortened_from_viper_line "${viper_line}")
    done <<< "$url_list"
    # set +x
}


alias unique_http_or_https_transport="grep 'http' | sort -u -t\/ -k4,4"
# `-u` for unique
# -t \: for colon delimited
# -k1,1 for key field 1

get_bitly_hashes() {
    # ONLY gets bit.ly hashes (for harpoon)
    # $1 == file from read_viper_url_file
    # $2 == output file to write location of thug daat
    cat "$1" | cut -d, -f 1| grep "bit\.ly" | sed 's/http[s]*:\/\/bit\.ly\/\(.*\)/\1/' > "$2"
}

read_email() {
    # Take a .eml email and open it up in mutt
    # sudo apt-get install mutt procmail
    local curdir=$(pwd)
    local tmpdir
    tmpdir=$(mktemp -dt "$(basename "$0").XXXXX")
    local eml_name
    eml_name=$(basename "$0")
    cp -f "$1" "${tmpdir}/${eml_name}"
    cd "${tmpdir}"
    formail -b < "${eml_name}" > "${eml_name}.mbox"
    neomutt -F '' -f "${eml_name}.mbox"
    cd "${curdir}"
    echo "Files Can be found in ${tmpdir}"
}

decode_qr() {
    # decode a QR code from an image
    # sudo apt-get install zbar-tools
    zbarimg "${1}"
}

apk_certificate() {
    keytool -list -printcert -jarfile "${1}"
}

apk_verify_signature() {
    jarsigner -verify -verbose:summary -certs "${1}"
}

search_dir_for_urls() {
    grep -r --only-matching --perl-regexp "http(s?):\/\/[^ \"\(\)\<\>]*" "${1}"
}


## Tor Support

# tmutt() {
#     # This really only is in place to remove the "Received: from" IP address leakage problem.
#     # Not expecting it does more than that
#     # See: tor wiki for info about how difficult this problem is.
#     torify neomutt "$@" 2>/dev/null
# }

alias mutt="run_mutt.sh"

# tor_wget() {
#     wget -e use_proxy=on -e http_proxy=http://localhost:8118 "$@"
# }


# tor_curl() {
#     local url="${1}"
#     local UA="${2}"
#     local LANG="${3}"
#     local ACCEPT="${4}"
#     local DNT="${5}"

#     if [ -z "${UA}" ]; then
#         local UA="Mozilla/5.0 (Windows NT 6.1; rv:45.0) Gecko/20100101 Firefox/45.0"
#     fi

#     if [ -z "${LANG}" ]; then
#         local LANG='Accept-Language: en-US,en;q=0.5'
#     fi

#     if [ -z "${ACCEPT}" ]; then
#         local ACCEPT='Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'
#     fi

#     if [ -z "${DNT}" ]; then
#         local DNT='DNT: 1'
#     fi

#     curl --proxy "socks5h://localhost:9150" -L --1.1 --compressed --user-agent "${UA}" -H "${LANG}" -H "${ACCEPT}" -H "${DNT}" "${url}"
# }

rip_dvd() {
    local VOB_PATH="$1" # VTS_01_1.VOB
    local AVI_PATH="$2" # ~/video_01_1
    # -f avi : force output format
    # -c:v libx264 : encode with the h264 codec to create small, but quality files
    # -g 300 : GOP size is 300 which means one intra frame every 10 seconds for 29.97fps input video
    avconv -i "${VOB_PATH}" -f avi -c:v libx264 -g 300 -bf 2 "${AVI_PATH}".avi

    # Note for mounting dvd's
    # sudo mount -o loop /dev/cdrom /media/cdrom/
}
alias vob_to_avi="rip_dvd"

alias pretty_xml="xmllint --format -"


# https://github.com/mathiasbynens/dotfiles/blob/master/.functions

# Create a data URL from a file
function dataurl() {
        local mimeType=$(file -b --mime-type "$1");
        if [[ $mimeType == text/* ]]; then
                mimeType="${mimeType};charset=utf-8";
        fi
        echo "data:${mimeType};base64,$(openssl base64 -in "$1" | tr -d '\n')";
}

# Compare original and gzipped file size
function gz() {
        local origsize=$(wc -c < "$1");
        local gzipsize=$(gzip -c "$1" | wc -c);
        local ratio=$(echo "$gzipsize * 100 / $origsize" | bc -l);
        printf "orig: %d bytes\n" "$origsize";
        printf "gzip: %d bytes (%2.2f%%)\n" "$gzipsize" "$ratio";
}

# Run `dig` and display the most useful info
function digga() {
        dig +nocmd "$1" any +multiline +noall +answer;
}

# Show all the names (CNs and SANs) listed in the SSL certificate
# for a given domain
function getcertnames() {
        if [ -z "${1}" ]; then
                echo "ERROR: No domain specified.";
                return 1;
        fi;

        local domain="${1}";
        echo "Testing ${domain}…";
        echo ""; # newline

        local tmp=$(echo -e "GET / HTTP/1.0\nEOT" \
                | openssl s_client -connect "${domain}:443" -servername "${domain}" 2>&1);

        if [[ "${tmp}" = *"-----BEGIN CERTIFICATE-----"* ]]; then
                local certText=$(echo "${tmp}" \
                        | openssl x509 -text -certopt "no_aux, no_header, no_issuer, no_pubkey, \
                        no_serial, no_sigdump, no_signame, no_validity, no_version");
                echo "Common Name:";
                echo ""; # newline
                echo "${certText}" | grep "Subject:" | sed -e "s/^.*CN=//" | sed -e "s/\/emailAddress=.*//";
                echo ""; # newline
                echo "Subject Alternative Name(s):";
                echo ""; # newline
                echo "${certText}" | grep -A 1 "Subject Alternative Name:" \
                        | sed -e "2s/DNS://g" -e "s/ //g" | tr "," "\n" | tail -n +2;
                return 0;
        else
                echo "ERROR: Certificate not found.";
                return 1;
        fi;
}

# `tre` is a shorthand for `tree` with hidden files and color enabled, ignoring
# the `.git` directory, listing directories first. The output gets piped into
# `less` with options to preserve color and line numbers, unless the output is
# small enough for one screen.
function tre() {
        tree -aC -I '.git|node_modules|bower_components' --dirsfirst "$@" | less -FRNX;
}
